{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DLFZ_ch04",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMo9VSg+visD3pfjMnMyLxi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anko191/Python_Kaggle/blob/master/DLFZ/DLFZ_ch04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdEutsIL4lSS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aea20509-05e7-4a86-c026-b310a12873c9"
      },
      "source": [
        "# 二乗和誤差\n",
        "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
        "t = [0,0,1,0,0,0,0,0,0,0]\n",
        "\n",
        "def sum_squared_error(y,t):\n",
        "    return 0.5 * np.sum((y-t)**2)\n",
        "sum_squared_error(np.array(y), np.array(t))"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.09750000000000003"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAV-mFWw5pdT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "baa2d46e-d8a3-463d-a0f9-5faa9e3c4044"
      },
      "source": [
        "# なぜか「7」の確率が最も高い場合\n",
        "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
        "sum_squared_error(np.array(y), np.array(t))"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5975"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oV99eH4D51aL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 交差エントロピ―誤差\n",
        "def cross_entropy_error(y, t):\n",
        "    delta = 1e-7\n",
        "    return -np.sum(t * np.log(y + delta))"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-sVP8Kh6wt2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "64b780c6-012f-42d2-a001-38d1cda12541"
      },
      "source": [
        "# np.arange(0.0, 6, 0.01)\n",
        "cross_entropy_error(np.array(y), np.array(t))"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.302584092994546"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_TEfquJ7YYE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "86d425b5-6bb4-4849-cc10-38ba7b85e90c"
      },
      "source": [
        "# ミニバッチ学習 100枚を無差別に取り出すぜ..!!!\n",
        "import sys, os\n",
        "sys.path.append(os.pardir)\n",
        "import numpy as np\n",
        "from mnist import load_mnist\n",
        "(x_train,t_train),(x_test,t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
        "t_test"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 1., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCN-nb1C8hBF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "da795f86-da07-40ac-c82d-21c8e3329665"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(t_train.shape)"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "(60000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eY-HjPmX9Bxq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_size = x_train.shape[0]\n",
        "batch_size = 10\n",
        "batch_mask = np.random.choice(train_size, batch_size)\n",
        "x_batch = x_train[batch_mask]\n",
        "t_batch = t_train[batch_mask]"
      ],
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdP75LDv9X80",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# バッチに対応されてるversion\n",
        "def cross_entropy_error(y, t):\n",
        "    if y.ndim == 1:\n",
        "        t = t.reshape(1, t.size)\n",
        "        y = y.reshape(1, y.size)\n",
        "    batch_size = y.shape[0]\n",
        "    return -np.sum(t * np.log(y + 1e-7)) / batch_size\n",
        "    # return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIUT-M_M9sES",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# numerical differentiation\n",
        "def numerical_diff(f, x):\n",
        "    h = 1e-4\n",
        "    return (f(x+h) - f(x-h)) / (2*h)"
      ],
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gBt0YDg_LML",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def function_1(x):\n",
        "    return 0.01*x**2 + 0.1*x\n"
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bGOsw-J_VT6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "329054e9-4401-4479-fcda-63ef90e3c365"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "x = np.arange(0.0,20.0,0.1)\n",
        "y = function_1(x)\n",
        "plt.plot(x,y)"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fb99ddfa358>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h42EazKs_dz6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c5e42a0f-b9be-4a65-fbbc-77814148c117"
      },
      "source": [
        "numerical_diff(function_1, 5)"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1999999999990898"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFN42Z-R_iwK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 偏微分\n",
        "def function_2(x):\n",
        "    return x[0] ** 2 + x[1] ** 2\n",
        "    # or return np.sum(x**2)"
      ],
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o78LEO-lQ0LY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f80ecbb0-2f8b-4b4e-9c88-66b0920dcf19"
      },
      "source": [
        "def function_tmp1(x0):\n",
        "    return x0 * x0 + 4.0 ** 2.0\n",
        "numerical_diff(function_tmp1, 3.0)"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.00000000000378"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rv3y_P6IRB1G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def numerical_gradient(f, x):\n",
        "    h = 1e-4\n",
        "    grad = np.zeros_like(x)\n",
        "    for idx in range(x.size):\n",
        "        tmp_val = x[idx]\n",
        "        # f(x+h)\n",
        "        x[idx] = tmp_val + h\n",
        "        fxh1 = f(x)\n",
        "        # f(x-h)\n",
        "        x[idx] = tmp_val - h\n",
        "        fxh2 = f(x)\n",
        "        \n",
        "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
        "        x[idx] = tmp_val # もとに戻す\n",
        "    return grad"
      ],
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWyH8q6RU29t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gradient_descent(f, init_x, lr = 0.01, step_num = 100):\n",
        "    x = init_x\n",
        "    for i in range(step_num):\n",
        "        grad = numerical_gradient(f, x)\n",
        "        x -= lr * grad\n",
        "    return x"
      ],
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXuT1y7Ho_Kz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def function_2(x):\n",
        "    return x[0] ** 2 + x[1] ** 2"
      ],
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcBjuGBSpE2L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "438f4026-97d9-4552-9dd4-b5bb61f2b07a"
      },
      "source": [
        "init_x = np.array([-3.0, 4.0])\n",
        "gradient_descent(function_2, init_x = init_x, lr = 0.1, step_num = 100)"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-6.11110793e-10,  8.14814391e-10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQZOb-tDpOPa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 真の値の最小値は (0,0) なので、勾配法によって、ほぼ正しい x^2 + y^2の最小値は(0,0)でしょ??"
      ],
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SK86XPk8pmTS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys, os\n",
        "sys.path.append(os.pardir)\n",
        "import numpy as np\n",
        "# softmax\n",
        "def softmax(a):\n",
        "    c = np.max(a)\n",
        "    exp_a = np.exp(a-c) # here.\n",
        "    sum_exp_a = np.sum(exp_a)\n",
        "    y = exp_a / sum_exp_a\n",
        "    return y\n",
        "# cross entropy error\n",
        "def cross_entropy_error(y, t):\n",
        "    if y.ndim == 1:\n",
        "        t = t.reshape(1, t.size)\n",
        "        y = y.reshape(1, y.size)\n",
        "    # one hot 表現の時、正解ラベルのインデックスに変換\n",
        "    if t.size == y.size:\n",
        "        t = t.argmax(axis = 1)\n",
        "    batch_size = y.shape[0]\n",
        "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size\n",
        "# def numerical_gradient(f, x):\n",
        "#     h = 1e-4\n",
        "#     grad = np.zeros_like(x)\n",
        "#     for idx in range(x.size):\n",
        "#         tmp_val = x[idx]\n",
        "#         # f(x+h)\n",
        "#         x[idx] = tmp_val + h\n",
        "#         fxh1 = f(x)\n",
        "#         # f(x-h)\n",
        "#         x[idx] = tmp_val - h\n",
        "#         fxh2 = f(x)\n",
        "        \n",
        "#         grad[idx] = (fxh1 - fxh2) / (2*h)\n",
        "#         x[idx] = tmp_val # もとに戻す\n",
        "#     return grad\n",
        "\n",
        "\n",
        "# ! renewed ! 多次元対応\n",
        "def numerical_gradient(f, x):\n",
        "    h = 1e-4\n",
        "    grad = np.zeros_like(x)\n",
        "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
        "    while not it.finished:\n",
        "        idx = it.multi_index\n",
        "        tmp_val = x[idx]\n",
        "        x[idx] = tmp_val + h\n",
        "        fxh1 = f(x)\n",
        "        \n",
        "        x[idx] = tmp_val - h\n",
        "        fxh2 = f(x)\n",
        "        grad[idx] = (fxh1-fxh2) / (2*h)\n",
        "\n",
        "        x[idx] = tmp_val\n",
        "        it.iternext()\n",
        "    return grad"
      ],
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkpHjiq2r-tf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class simpleNet:\n",
        "    def __init__(self):\n",
        "        self.W = np.random.randn(2,3) # ガウス分布で初期化\n",
        "    def predict(self, x):\n",
        "        return np.dot(x, self.W)\n",
        "    def loss(self, x, t):\n",
        "        z = self.predict(x)\n",
        "        y = softmax(z)\n",
        "        loss = cross_entropy_error(y, t)\n",
        "        return loss"
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnavxmXYtERJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = simpleNet()"
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_ArFW9ZtGIa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8bcd64d9-e326-45d6-f898-db23d89bdd36"
      },
      "source": [
        "print(net.W)"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-1.1779306  -0.77383853 -1.24178528]\n",
            " [-0.49509918 -0.02989912  0.54978036]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7dRBA3AtHRy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = np.array([0.6, 0.9])\n",
        "p = net.predict(x)"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8NynjExtKyL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7d9112d3-0dc2-429b-b548-8aeccb54c77e"
      },
      "source": [
        "print(p)"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-1.15234762 -0.49121233 -0.25026885]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78n5T6YCtLlR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cf26ed90-d293-4edc-a030-1c37481cd6f1"
      },
      "source": [
        "np.argmax(p)"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RsXcVbktOZN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "80ef5446-a636-48c4-dd84-55f76e7832f0"
      },
      "source": [
        "t = np.array([0,0,1])\n",
        "net.loss(x,t)"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7846368612021137"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-57O73PqtWIa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 勾配\n",
        "f = lambda w:net.loss(x,t)"
      ],
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUhfpajKtgEa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c7d784ae-6d05-4c89-f4c3-9d3a2a6bf489"
      },
      "source": [
        "x = np.array([0.6,0.9])\n",
        "t = np.array([0,0,1])\n",
        "net = simpleNet()\n",
        "dW = numerical_gradient(f, net.W)\n",
        "print(dW)"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.20293677  0.29813207 -0.50106885]\n",
            " [ 0.30440516  0.44719811 -0.75160327]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mwxbj8Zntjrp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TwoLayerNet:\n",
        "    def __init__(self, input_size, hidden_size, output_size, weight_init_std = 0.01):\n",
        "        # 重みの初期化\n",
        "        self.params = {}\n",
        "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
        "        self.params['b1'] = np.zeros(hidden_size)\n",
        "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
        "        self.params['b2'] = np.zeros(output_size)\n",
        "    def predict(self, x):\n",
        "        W1, W2 = self.params['W1'], self.params['W2']\n",
        "        b1, b2 = self.params['b1'], self.params['b2']\n",
        "        a1 = np.dot(x, W1) + b1\n",
        "        z1 = sigmoid(a1)\n",
        "        a2 = np.dot(z1, W2) + b2\n",
        "        y = softmax(a2)\n",
        "        return y\n",
        "    # x:inputdata, t:testdata\n",
        "    def loss(self, x, t):\n",
        "        y = self.predict(x)\n",
        "        return cross_entropy_error(y, t)\n",
        "    def accuracy(self, x, t):\n",
        "        y = self.predict(x)\n",
        "        y = np.argmax(axis = 1)\n",
        "        t = np.argmax(axis = 1)\n",
        "\n",
        "        accuracy = np.sum(y == t) / floa(x.shape[0])\n",
        "        return accuracy\n",
        "    # x, t\n",
        "    def numerical_gradient(self, x, t):\n",
        "        loss_W = lambda W:self.loss(x, t)\n",
        "        grads = {}\n",
        "        print('!hey')\n",
        "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
        "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
        "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
        "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
        "        return grads"
      ],
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Guh-PuXo0y5k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = TwoLayerNet(input_size = 784, hidden_size = 100, output_size=10)\n",
        "net.params['W1'].shape\n",
        "net.params['b1'].shape\n",
        "net.params['W2'].shape\n",
        "net.params['b2'].shape\n",
        "x = np.random.rand(100, 784)\n",
        "y = net.predict(x)\n",
        "#print(y)"
      ],
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AA-mbaaL135R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "f91e2445-2dbb-4ea2-981b-bafba7d849bd"
      },
      "source": [
        "x = np.random.rand(100, 784)\n",
        "t = np.random.rand(100,10) # ダミー正解モデル\n",
        "grads = net.numerical_gradient(x, t)\n",
        "print(grads['W1'].shape)\n",
        "print(grads['b1'].shape)\n",
        "print(grads['W2'].shape)\n",
        "print(grads['b2'].shape)"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "!hey\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-188-aa6c36f8b8d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m784\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# ダミー正解モデル\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-186-6adfea5c8930>\u001b[0m in \u001b[0;36mnumerical_gradient\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'!hey'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-176-5618bc17631c>\u001b[0m in \u001b[0;36mnumerical_gradient\u001b[0;34m(f, x)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mtmp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_val\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mfxh1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_val\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-186-6adfea5c8930>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(W)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# x, t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mloss_W\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'!hey'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-186-6adfea5c8930>\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# x:inputdata, t:testdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcross_entropy_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-186-6adfea5c8930>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0ma2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-62-f773c069d3ef>\u001b[0m in \u001b[0;36msigmoid\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# sigmoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d44OOV2B2L1p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid_grad(x):\n",
        "    return (1.0 - sigmoid(x)) * sigmoid(x)"
      ],
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cz1yTUF1NnNg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gradient(self, x, t):\n",
        "    W1, W2 = self.params['W1'], self.params['W2']\n",
        "    b1, b2 = self.params['b1'], self.params['b2']\n",
        "    grads = {}\n",
        "    batch_num = x.shape[0]\n",
        "    # forward\n",
        "    a1 = np.dot(x, W1) + b1\n",
        "    z1 = sigmoid(a1)\n",
        "    a2 = np.dot(z1, W2) + b2\n",
        "    y = softmax(a2)\n",
        "\n",
        "    # backword\n",
        "    dy = (y - t) / batch_num\n",
        "    grads['W2'] = np.dot(z1.T, dy)\n",
        "    grads['b2'] = np.sum(dy, axis = 0)\n",
        "    dz1 = np.dot(dy, W2.T)\n",
        "    da1 = sigmoid_grad(a1) * dz1\n",
        "    \n",
        "    grads['W1'] = np.dot(x.T, da1)\n",
        "    grads['b1'] = np.sum(da1, axis = 0)\n",
        "    return grads"
      ],
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_V-c8jYOTmS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}