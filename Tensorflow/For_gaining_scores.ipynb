{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "For_gaining_scores.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOtlDGJ5cyue1tnvln7fe8o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anko191/Python_Kaggle/blob/master/Tensorflow/For_gaining_scores.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74FZLY3zgjev"
      },
      "source": [
        "## 予測値をp_min ~ p_max の間に落とし込む"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyqSDKBfgjH-"
      },
      "source": [
        "p_min = 0.001\n",
        "p_max = 0.999"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LE9EUYs9lo7"
      },
      "source": [
        "def metric(y_true, y_pred):\n",
        "    y_pred = tf.clip_by_value(y_pred, p_min, p_max)\n",
        "    return -K.mean(y_true * K.log(y_pred) + (1 - y_true) * K.log(1 - y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FObbIv2g22O"
      },
      "source": [
        "## BinaryCrossentropyのlabel_smoothingを使う\n",
        "* import tensorflow.keras.losses as LOSS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShOsma6Yg3Iy"
      },
      "source": [
        "model.compile(optimizer = optimizer,\n",
        "                loss = LOSS.BinaryCrossentropy(label_smoothing = 0.001),\n",
        "                metrics = metric,\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEU1uOLVkhzS"
      },
      "source": [
        "## なんで？？\n",
        "* ref - https://www.kaggle.com/c/lish-moa/discussion/185593\n",
        "    * a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCn-d_EGmtT0"
      },
      "source": [
        "## MultilabelStratifiedShuffleSplit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpZOXhFqklN1"
      },
      "source": [
        "import sys\n",
        "sys.path.append('../input/iterative-stratification/iterative-stratification-master')\n",
        "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold, MultilabelStratifiedShuffleSplit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0Gj34T3mysk"
      },
      "source": [
        "def MSKF(r_sub, res, n_splits = 4):\n",
        "    for seed in seeds:\n",
        "        for num , (train_idx, valid_idx) in tqdm(enumerate(MultilabelStratifiedShuffleSplit(n_splits = n_splits,\n",
        "                                                                      random_state = seed,\n",
        "                                                                      test_size = 0.2).split(train_target, train_target))):\n",
        "            print(f'Multilabels - Fold : {num}')\n",
        "\n",
        "            model = get_model(len(train.columns))\n",
        "            # leakageするのでやめましょう\n",
        "\n",
        "            checkpoint_path = f'now : {i}_Fold:{num}.hdf5'\n",
        "\n",
        "            modelcheckpoint = ModelCheckpoint(checkpoint_path,\n",
        "                                                      monitor='val_metric',\n",
        "                                                      verbose = 0,\n",
        "                                                      save_best_only=True,\n",
        "                                                      save_weights_only = True,\n",
        "                                                      mode = 'min', # 現象させろperiod = 1\n",
        "                                                      )\n",
        "\n",
        "            reduce_lr = ReduceLROnPlateau(monitor='val_metric',\n",
        "                                          # lr = 0.1,\n",
        "                                          factor=0.5,\n",
        "                                          patience = 4,\n",
        "                                          epsilon=1e-4,\n",
        "                                          verbose = 1,\n",
        "                                          mode = 'min')\n",
        "            ES = keras.callbacks.EarlyStopping(monitor='val_metric',\n",
        "                                          min_delta=0.00001,\n",
        "                                          patience=8,\n",
        "                                          verbose=2,\n",
        "                                          mode='min')\n",
        "            # print(train_idx) 横軸のindexかよ\n",
        "            history = model.fit(train.values[train_idx],\n",
        "                     train_target.values[train_idx],\n",
        "                     validation_data = (train.values[valid_idx],\n",
        "                                        train_target.values[valid_idx]),\n",
        "                     epochs = 45,\n",
        "                     batch_size = 128,\n",
        "                     callbacks = [modelcheckpoint, reduce_lr, ES],\n",
        "                     # verbose = 2,\n",
        "                     )\n",
        "            hists.append(history)\n",
        "            \n",
        "            \n",
        "            model.load_weights(checkpoint_path)\n",
        "            \n",
        "            \n",
        "            test_pred = model.predict(test.values)\n",
        "            val_pred = model.predict(train.values[valid_idx])\n",
        "\n",
        "            r_sub.loc[:,train_target.columns] += test_pred\n",
        "            res.loc[valid_idx, train_target.columns] += val_pred\n",
        "            print(' - - - - - - - - - (´・ω・｀) - - - - - - - -')\n",
        "    r_sub.loc[:, train_target.columns] /= ((num+1) * n_seeds)\n",
        "    res.loc[:, train_target.columns] /= n_seeds\n",
        "    return r_sub, res"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}